
ABSTRACT

We present OmniVec, a unified embedding framework that integrates emotion-awareness,
temporal dynamics, and causality modeling into a single multi-task learning architecture.
Unlike traditional static embeddings (Word2Vec, FastText), OmniVec jointly optimizes
for multiple objectives: skip-gram prediction, emotion classification, temporal consistency,
and causality relation modeling. 

We evaluate OmniVec on sentiment analysis (IMDB) and emotion classification tasks,
demonstrating significant improvements over baseline methods. OmniVec achieves
0.6360 accuracy on sentiment classification
(-23.70% improvement over best baseline) and 
0.6500 accuracy on emotion classification
(+16.91% improvement). 

Ablation studies confirm that each component contributes meaningfully to performance,
with the emotion-aware layer providing the largest gains on emotion-related tasks.
Qualitative analysis reveals that OmniVec produces more semantically coherent clusters
for emotion words and better captures nuanced relationships. Our framework demonstrates
that multi-task learning with diverse linguistic signals can significantly enhance
embedding quality for downstream NLP applications.

KEYWORDS: Word Embeddings, Multi-task Learning, Emotion Analysis, Temporal Semantics,
Causality Modeling
    